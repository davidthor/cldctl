---
title: "Migrating an Existing App to cldctl"
description: "Adopt existing cloud infrastructure into cldctl without downtime using the import command"
---

# Migrating an Existing App to cldctl

This guide walks through migrating an application that was **not** built with cldctl — a Next.js frontend, Express API backend, and PostgreSQL database already running on AWS — into a fully cldctl-managed deployment. You will define cldctl components for the first time and then use `cldctl import` to adopt the existing cloud resources into state without destroying or recreating anything.

## Before You Start

You have an application already running on AWS with:

| Layer | Technology | AWS Resource |
|-------|-----------|--------------|
| Frontend | Next.js | ECS Fargate service `acme-web` |
| API | Express.js | ECS Fargate service `acme-api` |
| Database | PostgreSQL 16 | RDS instance `acme-production-db` |

These resources were provisioned manually (or via standalone Terraform) and are serving production traffic. Your goal is to bring them under cldctl management so future changes flow through `cldctl deploy`.

<Warning>
Import does **not** provision or modify cloud resources. It records existing infrastructure in cldctl's state so that subsequent deploys can manage it. There is no downtime.
</Warning>

## Step 1: Define Your Components

Even though the infrastructure already exists, cldctl needs a component definition to understand **what** the application requires. Create a `cloud.component.yml` in each project.

### Frontend Component

```yaml
# frontend/cloud.component.yml
dependencies:
  api:
    component: ghcr.io/acme/api

databases:
  main:
    type: postgres:^16

functions:
  web:
    src:
      path: .
      framework: nextjs
    environment:
      DATABASE_URL: ${{ databases.main.url }}
      NEXT_PUBLIC_API_URL: ${{ dependencies.api.routes.api.url }}

routes:
  main:
    type: http
    function: web
```

<Note>
The `dependencies` block declares that the frontend depends on the API component. At runtime, `${{ dependencies.api.routes.api.url }}` resolves to the API's route URL. The `databases` block declares a dependency on PostgreSQL — at import time you will map this to the existing RDS instance rather than creating a new one.
</Note>

### API Component

```yaml
# api/cloud.component.yml
variables:
  jwt_secret:
    description: "JWT signing secret"
    required: true
    sensitive: true

databases:
  main:
    type: postgres:^16

builds:
  api:
    context: .
    dockerfile: Dockerfile

deployments:
  api:
    image: ${{ builds.api.image }}
    environment:
      DATABASE_URL: ${{ databases.main.url }}
      JWT_SECRET: ${{ variables.jwt_secret }}
      PORT: "3000"
    cpu: "0.5"
    memory: "1Gi"

services:
  api:
    deployment: api
    port: 3000

routes:
  api:
    type: http
    service: api
```

### Build the Artifacts

Even though you already have running containers, cldctl needs OCI artifacts so it knows each component's resource graph:

```bash
# Build component artifacts (this packages the YAML + source, it does NOT deploy)
cldctl build component ./frontend -t ghcr.io/acme/frontend:v1.0.0
cldctl build component ./api -t ghcr.io/acme/api:v1.0.0

# Push to your registry
cldctl push component ghcr.io/acme/frontend:v1.0.0
cldctl push component ghcr.io/acme/api:v1.0.0
```

## Step 2: Deploy the Datacenter (with Imports)

cldctl needs a datacenter to know **how** resources are provisioned. If the datacenter template has root-level modules (VPC, networking, ALB), those resources already exist in your AWS account. Use `--import-file` to adopt them during the deploy — cldctl imports the mapped resources into state first, then runs the normal deploy which sees them as existing and updates in place:

```bash
# Pull the official AWS ECS datacenter template
cldctl pull datacenter ghcr.io/cldctl/aws-ecs:latest

# Deploy with existing root modules imported atomically
cldctl deploy datacenter prod-dc ghcr.io/cldctl/aws-ecs:latest \
  --var aws_region=us-east-1 \
  --var vpc_id=vpc-0abc123def456 \
  --var ecs_cluster_arn=arn:aws:ecs:us-east-1:123456789:cluster/acme \
  --var domain=acme.com \
  --import-file import-datacenter.yml
```

The import file maps each root-level module to existing cloud resource IDs:

```yaml
# import-datacenter.yml
modules:
  vpc:
    - address: aws_vpc.main
      id: "vpc-0abc123def456"
    - address: aws_subnet.public[0]
      id: "subnet-aaa111"
    - address: aws_subnet.public[1]
      id: "subnet-bbb222"
  alb:
    - address: aws_lb.main
      id: "arn:aws:elasticloadbalancing:us-east-1:123456789:loadbalancer/app/acme-alb/abc123"
```

This is a single atomic operation — the datacenter is never in a half-deployed state. Modules listed in the import file are imported, modules not listed are provisioned normally.

<Note>
If the datacenter template has no root-level modules (some templates only define hooks and rely on pre-existing shared infrastructure via variables), you can omit `--import-file` entirely.
</Note>

## Step 3: Create the Environment

Create a cldctl environment that represents your production deployment:

```bash
cldctl create environment production -d prod-dc
```

This creates an empty environment in state. The next step fills it with your existing resources.

## Step 4: Discover IaC Resource Addresses

Before writing mapping files, you need to know the IaC resource addresses used by the datacenter's hook modules. Use `cldctl audit datacenter --modules` to discover them directly from the template:

```bash
cldctl audit datacenter ghcr.io/cldctl/aws-ecs:latest --modules
```

```
IaC Resource Addresses
============================================================

Use these addresses in import mapping files (--import-file)
or --map flags to map existing cloud resources to IaC state.

Hook: database
------------------------------------------------------------
  when: element(split(":", node.inputs.type), 0) == "postgres"

  module "rds-database" (plugin=opentofu)
    Resources (use as --map addresses):
      random_password.this
      aws_db_subnet_group.this
      aws_db_instance.this

Hook: deployment
------------------------------------------------------------

  module "ecs-service" (plugin=opentofu)
    Resources (use as --map addresses):
      aws_ecs_task_definition.this
      aws_ecs_service.this

Hook: service
------------------------------------------------------------

  module "alb-target-group" (plugin=opentofu)
    Resources (use as --map addresses):
      aws_lb_target_group.this

Hook: route
------------------------------------------------------------

  module "alb-listener-rule" (plugin=opentofu)
    Resources (use as --map addresses):
      aws_lb_listener_rule.this
```

The output shows every Terraform/OpenTofu `resource` block and every native module resource. These are the addresses you use in your mapping files.

<Tip>
For a high-level overview without resource addresses (hooks, modules, variables), omit `--modules`:

```bash
cldctl audit datacenter ghcr.io/cldctl/aws-ecs:latest
```

You can also audit the component template to see resource keys for the mapping file:

```bash
cldctl audit component ghcr.io/acme/api:v1.0.0
```
</Tip>

## Step 5: Write the Import Mapping File

Create a YAML mapping file for each component describing which cloud resources map to which IaC addresses.

### API Component Mapping

```yaml
# import-api.yml
resources:
  database.main:
    - address: aws_db_instance.main
      id: "acme-production-db"
    - address: aws_security_group.db
      id: "sg-0db1234567890"
  deployment.api:
    - address: aws_ecs_service.main
      id: "arn:aws:ecs:us-east-1:123456789:service/acme/acme-api"
    - address: aws_ecs_task_definition.main
      id: "arn:aws:ecs:us-east-1:123456789:task-definition/acme-api:42"
  service.api:
    - address: aws_lb_target_group.main
      id: "arn:aws:elasticloadbalancing:us-east-1:123456789:targetgroup/acme-api/abc123"
  route.api:
    - address: aws_lb_listener_rule.main
      id: "arn:aws:elasticloadbalancing:us-east-1:123456789:listener-rule/app/acme-alb/abc/def/rule123"
```

### Frontend Component Mapping

```yaml
# import-frontend.yml
resources:
  database.main:
    - address: aws_db_instance.main
      id: "acme-production-db"
    - address: aws_security_group.db
      id: "sg-0db1234567890"
  function.web:
    - address: aws_lambda_function.main
      id: "acme-web"
  route.main:
    - address: aws_lb_listener_rule.main
      id: "arn:aws:elasticloadbalancing:us-east-1:123456789:listener-rule/app/acme-alb/abc/def/rule456"
```

<Tip>
You can find AWS resource IDs in the AWS Console, via the AWS CLI (`aws ecs describe-services`, `aws rds describe-db-instances`, etc.), or from your existing Terraform state files.
</Tip>

## Step 6: Deploy Components with Import

Deploy each component and import existing resources in one atomic step using `--import-file`. Start with the API (since the frontend depends on it):

### Deploy and Import the API

```bash
cldctl deploy component ghcr.io/acme/api:v1.0.0 \
  -d prod-dc -e production \
  --var jwt_secret=$JWT_SECRET \
  --import-file import-api.yml
```

cldctl imports the mapped resources into state, then runs the normal deploy. Since every resource already has state from the import, the deploy reconciles rather than creating duplicates:

```
[import] Importing existing resources for 4 resource(s)...
  Importing database.main (2 IaC resource(s))...
  Verifying import...
  database.main: imported successfully (no drift)
  Importing deployment.api (2 IaC resource(s))...
  Verifying import...
  deployment.api: imported successfully (no drift)
  Importing service.api (1 IaC resource(s))...
  Verifying import...
  service.api: imported successfully (no drift)
  Importing route.api (1 IaC resource(s))...
  Verifying import...
  route.api: imported successfully (no drift)

Plan Summary:
  Environment: production
  Datacenter:  prod-dc

No changes required.

[success] Deployed api to production
```

### Deploy and Import the Frontend

```bash
cldctl deploy component ghcr.io/acme/frontend:v1.0.0 \
  -d prod-dc -e production \
  --import-file import-frontend.yml
```

<Note>
The `--import-file` flag is only needed on the **first** deploy for each component. Subsequent deploys (version updates, config changes) use the normal `deploy component` without it.
</Note>

## Step 7: Verify the Import

After importing, use `cldctl inspect` to verify everything looks correct:

```bash
# Check the environment
cldctl inspect production

# Check the API component
cldctl inspect production/api

# Check a specific resource
cldctl inspect production/api/database.main
```

You should see all resources in `ready` status with their outputs populated (database URLs, service endpoints, etc.).

List the components to confirm:

```bash
cldctl list component -e production -d prod-dc
```

```
NAME        VERSION                          RESOURCES   STATUS
api         ghcr.io/acme/api:v1.0.0         4           ready
frontend    ghcr.io/acme/frontend:v1.0.0    3           ready
```

## Step 8: Deploy Future Changes Through cldctl

Now that state is imported, all future changes go through `cldctl deploy`. For example, to deploy a new API version:

```bash
# Build the new version
cldctl build component ./api -t ghcr.io/acme/api:v1.1.0
cldctl push component ghcr.io/acme/api:v1.1.0

# Deploy — cldctl knows what exists and only updates what changed
cldctl deploy component ghcr.io/acme/api:v1.1.0 -e production -d prod-dc
```

cldctl compares the new component definition against the imported state and creates a plan that only modifies what changed — no unnecessary recreation.

## Alternative: Single-File Environment Import

If you prefer to import everything at once instead of component-by-component, use the environment-level import:

```yaml
# import-production.yml
components:
  api:
    source: ghcr.io/acme/api:v1.0.0
    variables:
      jwt_secret: "${JWT_SECRET}"
    resources:
      database.main:
        - address: aws_db_instance.main
          id: "acme-production-db"
        - address: aws_security_group.db
          id: "sg-0db1234567890"
      deployment.api:
        - address: aws_ecs_service.main
          id: "arn:aws:ecs:us-east-1:123456789:service/acme/acme-api"
        - address: aws_ecs_task_definition.main
          id: "arn:aws:ecs:us-east-1:123456789:task-definition/acme-api:42"
      service.api:
        - address: aws_lb_target_group.main
          id: "arn:aws:elasticloadbalancing:us-east-1:123456789:targetgroup/acme-api/abc123"
      route.api:
        - address: aws_lb_listener_rule.main
          id: "arn:aws:elasticloadbalancing:us-east-1:123456789:listener-rule/app/acme-alb/abc/def/rule123"
  frontend:
    source: ghcr.io/acme/frontend:v1.0.0
    resources:
      database.main:
        - address: aws_db_instance.main
          id: "acme-production-db"
        - address: aws_security_group.db
          id: "sg-0db1234567890"
      function.web:
        - address: aws_lambda_function.main
          id: "acme-web"
      route.main:
        - address: aws_lb_listener_rule.main
          id: "arn:aws:elasticloadbalancing:us-east-1:123456789:listener-rule/app/acme-alb/abc/def/rule456"
```

```bash
cldctl import environment production \
  -d prod-dc \
  --mapping import-production.yml
```

## Handling Drift

After import, cldctl may detect **drift** — differences between the imported state and the actual infrastructure. This can happen when the existing resources were configured slightly differently than the datacenter's module expects.

```
  deployment.api: imported with 2 drift(s) detected
```

To resolve drift, run a deploy to reconcile:

```bash
cldctl deploy component ghcr.io/acme/api:v1.0.0 -e production -d prod-dc
```

This brings the actual infrastructure into alignment with the cldctl-managed configuration.

## Partial Import

You don't have to import everything at once. Common migration patterns:

1. **Database first** — Import the database so cldctl manages backups and connection strings, while keeping deployments manual.
2. **One component at a time** — Import the API first, verify it works, then import the frontend.
3. **New environments first** — Use cldctl for staging (fresh deploy), then import production once you're confident.

Resources not included in the mapping file are simply absent from state. A subsequent `cldctl deploy` will create them fresh if the component definition includes them.

## Summary

| Step | Command | What It Does |
|------|---------|-------------|
| 1 | Write `cloud.component.yml` | Describe what each app needs |
| 2 | `cldctl build component` | Package the component definition |
| 3 | `cldctl deploy datacenter --import-file` | Deploy datacenter, importing existing root modules |
| 4 | `cldctl audit datacenter --modules` | Discover IaC resource addresses for mapping files |
| 5 | `cldctl create environment` | Create an empty environment |
| 6 | Write mapping YAML | Map cloud resource IDs to IaC addresses |
| 7 | `cldctl deploy component --import-file` | Deploy component, importing existing resources |
| 8 | `cldctl inspect` | Verify the import |
| 9 | `cldctl deploy component` | Make future changes through cldctl |

## Related Guides

<CardGroup cols={2}>
  <Card title="Import CLI Reference" icon="download" href="/cli/import/resource">
    Full command reference for all import subcommands
  </Card>
  <Card title="AWS ECS Datacenter" icon="aws" href="/guides/datacenters/aws-ecs">
    Official AWS ECS Fargate datacenter template
  </Card>
  <Card title="Next.js App" icon="react" href="/guides/components/nextjs-app">
    Building a Next.js component from scratch
  </Card>
  <Card title="Managing Environments" icon="layer-group" href="/guides/managing-environments">
    Day-to-day environment operations
  </Card>
</CardGroup>
